{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Data Mining Lab:2019-2023 Batch**","metadata":{"id":"FfJltntgdDAN"}},{"cell_type":"markdown","source":"**Semester - 6: Final Project: True vs Fake and Cleaning News Detection**","metadata":{}},{"cell_type":"markdown","source":"**Name: Dipesh Singla\nRoll: CO19322**\n","metadata":{}},{"cell_type":"markdown","source":"**Keywords: True and Fake News,Data Mining, Twitter, Google News Vector, word2vec gensim model**","metadata":{}},{"cell_type":"markdown","source":"# WHY FAKE NEWS IS A PROBLEM?\n**Fake news is defined as misinformation, disinformation, or mal-information that spreads by word of mouth, conventional media, and, more recently, digital modes of communication such as manipulated films, memes, unconfirmed adverts, and social media disseminated rumours. Fake news on social media has become a severe concern, with the potential for it to lead to mob violence, suicides, and other negative outcomes as a result of disinformation propagated on social media.**\n","metadata":{}},{"cell_type":"markdown","source":"**Motivation:** In this ever increasing social world we see lots of news circulating may it be on social media\nplatforms or on the internet across the globe. So there is a need to classify how can one be sure whether\nthe news is true i.e. is genuine and can be trusted upon from our existing Machine Learning Models and\nDeep Learning Algorithms. We have also worked on a reasearch of how various social networking sites\nlikeTwitter make their algorithm work to get to know the actual facts about a particular news which helped\nus carrying this idea forward.","metadata":{}},{"cell_type":"markdown","source":"**Use Case:** To visualize, classify, predict and compare various models/ prepocessing\nalgorithms to check whether a news is true or fake based on a given dataset.","metadata":{}},{"cell_type":"markdown","source":"**Data Sets**\n1. https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n2. https://www.kaggle.com/datasets/sandreds/googlenewsvectorsnegative300\n","metadata":{}},{"cell_type":"markdown","source":"# Library Imports","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport re\nfrom wordcloud import WordCloud","metadata":{"id":"KsRqEzY_dDAZ","execution":{"iopub.status.busy":"2022-05-21T15:43:02.388720Z","iopub.execute_input":"2022-05-21T15:43:02.389004Z","iopub.status.idle":"2022-05-21T15:43:04.235895Z","shell.execute_reply.started":"2022-05-21T15:43:02.388976Z","shell.execute_reply":"2022-05-21T15:43:04.235217Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"id":"m5Ac0QZWo-KD","execution":{"iopub.status.busy":"2022-05-21T15:43:04.237909Z","iopub.execute_input":"2022-05-21T15:43:04.238193Z","iopub.status.idle":"2022-05-21T15:43:10.017740Z","shell.execute_reply.started":"2022-05-21T15:43:04.238161Z","shell.execute_reply":"2022-05-21T15:43:10.017000Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Exploring Fake News","metadata":{"id":"YapFgrosdDBf"}},{"cell_type":"code","source":"fake = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")","metadata":{"id":"_bNLlXdWdDBn","execution":{"iopub.status.busy":"2022-05-21T15:43:10.021193Z","iopub.execute_input":"2022-05-21T15:43:10.021427Z","iopub.status.idle":"2022-05-21T15:43:10.968992Z","shell.execute_reply.started":"2022-05-21T15:43:10.021402Z","shell.execute_reply":"2022-05-21T15:43:10.968234Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"fake.head()","metadata":{"id":"3arpkQWfdDCS","outputId":"84c7ffa4-b00b-414e-d1b2-5b8d83d9e2c8","execution":{"iopub.status.busy":"2022-05-21T15:43:10.971316Z","iopub.execute_input":"2022-05-21T15:43:10.971552Z","iopub.status.idle":"2022-05-21T15:43:10.997864Z","shell.execute_reply.started":"2022-05-21T15:43:10.971527Z","shell.execute_reply":"2022-05-21T15:43:10.997116Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Counting by Subjects ","metadata":{}},{"cell_type":"code","source":"for key,count in fake.subject.value_counts().iteritems():\n    print(f\"{key}:\\t{count}\")\n    \n#Getting Total Rows\nprint(f\"Total Records:\\t{fake.shape[0]}\")","metadata":{"id":"CXeCGdsAdDDC","outputId":"1892de64-c58a-4035-b5e6-cefaac48ddbc","execution":{"iopub.status.busy":"2022-05-21T15:43:11.001156Z","iopub.execute_input":"2022-05-21T15:43:11.001403Z","iopub.status.idle":"2022-05-21T15:43:11.017748Z","shell.execute_reply.started":"2022-05-21T15:43:11.001373Z","shell.execute_reply":"2022-05-21T15:43:11.016486Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.countplot(\"subject\", data=fake)\nplt.show()","metadata":{"id":"tt3u2XJ5dDDs","outputId":"c4ab6c8d-91e1-4463-96b2-44bb7b21b502","execution":{"iopub.status.busy":"2022-05-21T15:43:11.021712Z","iopub.execute_input":"2022-05-21T15:43:11.022268Z","iopub.status.idle":"2022-05-21T15:43:11.176974Z","shell.execute_reply.started":"2022-05-21T15:43:11.022177Z","shell.execute_reply":"2022-05-21T15:43:11.176257Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Word Cloud","metadata":{}},{"cell_type":"code","source":"text = ''\nfor news in fake.text.values:\n    text += f\" {news}\"\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()\ndel text","metadata":{"id":"6SL6XlPCdDEp","outputId":"aa585d7d-1d14-427e-e996-1cf81e428c77","execution":{"iopub.status.busy":"2022-05-21T15:43:11.178167Z","iopub.execute_input":"2022-05-21T15:43:11.178604Z","iopub.status.idle":"2022-05-21T15:44:06.503565Z","shell.execute_reply.started":"2022-05-21T15:43:11.178568Z","shell.execute_reply":"2022-05-21T15:44:06.502793Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Exploring Real/ True News","metadata":{"id":"7wjJakMydDF_"}},{"cell_type":"code","source":"real = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")\nreal.head()","metadata":{"id":"ns94H6hsdDGL","outputId":"b7b61aa4-088a-4ccc-960c-4beb9485ca14","execution":{"iopub.status.busy":"2022-05-21T15:44:06.504599Z","iopub.execute_input":"2022-05-21T15:44:06.504832Z","iopub.status.idle":"2022-05-21T15:44:07.493286Z","shell.execute_reply.started":"2022-05-21T15:44:06.504804Z","shell.execute_reply":"2022-05-21T15:44:07.492590Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Difference in Text\nReal news seems to have source of publication which is not present in fake news set\n\nLooking at the data:\n- most of text contains reuters information such as \"**WASHINGTON (Reuters)**\".\n- Some text are tweets from Twitter \n- Few text do not contain any publication info","metadata":{"id":"UbXKpzl8dDHU"}},{"cell_type":"markdown","source":"# Cleaning Data\nRemoving Reuters or Twitter Tweet information from the text \n\n- Text can be splitted only once at \" - \" which is always present after mentioning source of publication, this gives us publication part and text part\n- If we do not get text part, this means publication details was't given for that record\n- The Twitter tweets always have same source, a long text of max 259 characters ","metadata":{"id":"tliOxHb7dDHg"}},{"cell_type":"markdown","source":"# Creating list of index that do not have publication part","metadata":{}},{"cell_type":"code","source":"unknown_publishers = []\nfor index,row in enumerate(real.text.values):\n    try:\n        record = row.split(\" -\", maxsplit=1)\n        #if no text part is present, following will give error\n        record[1]\n        #if len of piblication part is greater than 260\n        #following will give error, ensuring no text having \"-\" in between is counted\n        assert(len(record[0]) < 260)\n    except:\n        unknown_publishers.append(index)","metadata":{"id":"wTxfBZkedDH2","execution":{"iopub.status.busy":"2022-05-21T15:44:07.494683Z","iopub.execute_input":"2022-05-21T15:44:07.494936Z","iopub.status.idle":"2022-05-21T15:44:07.542709Z","shell.execute_reply.started":"2022-05-21T15:44:07.494905Z","shell.execute_reply":"2022-05-21T15:44:07.542034Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# List of indices where publisher is not mentioned","metadata":{}},{"cell_type":"code","source":"real.iloc[unknown_publishers].text\n#true, they do not have text like \"WASHINGTON (Reuters)\"","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:44:07.544133Z","iopub.execute_input":"2022-05-21T15:44:07.544418Z","iopub.status.idle":"2022-05-21T15:44:07.554220Z","shell.execute_reply.started":"2022-05-21T15:44:07.544384Z","shell.execute_reply":"2022-05-21T15:44:07.553503Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"While looking at texts that do not contain publication info such as which reuter, we noticed one thing.\n\n**Text at index 8970 is empty**","metadata":{}},{"cell_type":"code","source":"real.iloc[8970]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:44:07.557027Z","iopub.execute_input":"2022-05-21T15:44:07.557325Z","iopub.status.idle":"2022-05-21T15:44:07.564941Z","shell.execute_reply.started":"2022-05-21T15:44:07.557300Z","shell.execute_reply":"2022-05-21T15:44:07.564224Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Seperating Publication info, from actual text","metadata":{}},{"cell_type":"code","source":"publisher = []\ntmp_text = []\nfor index,row in enumerate(real.text.values):\n    if index in unknown_publishers:\n        #Add unknown of publisher not mentioned\n        tmp_text.append(row)\n        \n        publisher.append(\"Unknown\")\n        continue\n    record = row.split(\" -\", maxsplit=1)\n    publisher.append(record[0])\n    tmp_text.append(record[1])","metadata":{"id":"Xw7Ec258dDIx","execution":{"iopub.status.busy":"2022-05-21T15:44:07.566261Z","iopub.execute_input":"2022-05-21T15:44:07.566694Z","iopub.status.idle":"2022-05-21T15:44:07.656566Z","shell.execute_reply.started":"2022-05-21T15:44:07.566658Z","shell.execute_reply":"2022-05-21T15:44:07.655902Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Replace existing text column with new text","metadata":{}},{"cell_type":"markdown","source":"Add seperate column for publication info","metadata":{}},{"cell_type":"code","source":"real[\"publisher\"] = publisher\nreal[\"text\"] = tmp_text\n\ndel publisher, tmp_text, record, unknown_publishers","metadata":{"id":"ieCzo5pYdDJU","execution":{"iopub.status.busy":"2022-05-21T15:44:07.657861Z","iopub.execute_input":"2022-05-21T15:44:07.658123Z","iopub.status.idle":"2022-05-21T15:44:07.671822Z","shell.execute_reply.started":"2022-05-21T15:44:07.658093Z","shell.execute_reply":"2022-05-21T15:44:07.670589Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"real.head()","metadata":{"id":"lGqTE2qtdDJo","outputId":"e7600469-ff61-4c3e-b35e-89fd0804099f","execution":{"iopub.status.busy":"2022-05-21T15:44:07.674320Z","iopub.execute_input":"2022-05-21T15:44:07.674635Z","iopub.status.idle":"2022-05-21T15:44:07.690811Z","shell.execute_reply.started":"2022-05-21T15:44:07.674599Z","shell.execute_reply":"2022-05-21T15:44:07.690252Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"New column called \"Publisher\" has been added.\n","metadata":{}},{"cell_type":"markdown","source":"# Checking for rows with empty text like row:8970","metadata":{}},{"cell_type":"code","source":"[index for index,text in enumerate(real.text.values) if str(text).strip() == '']","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:44:07.692184Z","iopub.execute_input":"2022-05-21T15:44:07.692627Z","iopub.status.idle":"2022-05-21T15:44:07.720071Z","shell.execute_reply.started":"2022-05-21T15:44:07.692594Z","shell.execute_reply":"2022-05-21T15:44:07.719431Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#dropping this record\nreal = real.drop(8970, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:44:07.721613Z","iopub.execute_input":"2022-05-21T15:44:07.721911Z","iopub.status.idle":"2022-05-21T15:44:07.731876Z","shell.execute_reply.started":"2022-05-21T15:44:07.721877Z","shell.execute_reply":"2022-05-21T15:44:07.731300Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Checking for the same in fake news","metadata":{}},{"cell_type":"code","source":"empty_fake_index = [index for index,text in enumerate(fake.text.values) if str(text).strip() == '']\nprint(f\"No of empty rows: {len(empty_fake_index)}\")\nfake.iloc[empty_fake_index].tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:44:07.733366Z","iopub.execute_input":"2022-05-21T15:44:07.733665Z","iopub.status.idle":"2022-05-21T15:44:07.762329Z","shell.execute_reply.started":"2022-05-21T15:44:07.733631Z","shell.execute_reply":"2022-05-21T15:44:07.761579Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**630 Rows in Fake news with empty text**\n\nI've also observed a lot of CPATIAL-CASES in bogus news. Could keep letter cases, however we'll be utilising Google's pretrained word2vec vectors later on, which have well-formed lower case words. We will try to use lower case.\n\nThe text for these rows appears to be included in the title. Let's combine the title and text to solve these problems.","metadata":{}},{"cell_type":"markdown","source":"# Getting Total Rows","metadata":{}},{"cell_type":"code","source":"print(f\"Total Records:\\t{real.shape[0]}\")\n\n# Counting by Subjects \nfor key,count in real.subject.value_counts().iteritems():\n  print(f\"{key}:\\t{count}\")","metadata":{"id":"Ncknf-UPdDKQ","outputId":"f83f054e-1be0-4dab-d5f8-7d95a4e02257","execution":{"iopub.status.busy":"2022-05-21T15:44:07.763732Z","iopub.execute_input":"2022-05-21T15:44:07.764008Z","iopub.status.idle":"2022-05-21T15:44:07.774593Z","shell.execute_reply.started":"2022-05-21T15:44:07.763975Z","shell.execute_reply":"2022-05-21T15:44:07.773681Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=\"subject\", data=real)\nplt.show()","metadata":{"id":"F7hyf09XdDKg","outputId":"668ffd97-03e1-4ed8-fc5d-08c2e7e3f2b5","execution":{"iopub.status.busy":"2022-05-21T15:44:07.775964Z","iopub.execute_input":"2022-05-21T15:44:07.776561Z","iopub.status.idle":"2022-05-21T15:44:07.878112Z","shell.execute_reply.started":"2022-05-21T15:44:07.776459Z","shell.execute_reply":"2022-05-21T15:44:07.877557Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# WordCloud For Real News","metadata":{}},{"cell_type":"code","source":"text = ''\nfor news in real.text.values:\n    text += f\" {news}\"\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(str(text))\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()\ndel text","metadata":{"id":"8vZOUiSJdDKz","outputId":"10039276-931d-4aa1-9d87-c8c497a345be","execution":{"iopub.status.busy":"2022-05-21T15:44:07.879185Z","iopub.execute_input":"2022-05-21T15:44:07.879439Z","iopub.status.idle":"2022-05-21T15:44:57.764027Z","shell.execute_reply.started":"2022-05-21T15:44:07.879407Z","shell.execute_reply":"2022-05-21T15:44:57.761638Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Text","metadata":{"id":"31IETzH6dDLR"}},{"cell_type":"markdown","source":"# Adding class Information","metadata":{}},{"cell_type":"code","source":"real[\"class\"] = 1\nfake[\"class\"] = 0","metadata":{"id":"dJpU7O2OdDLT","execution":{"iopub.status.busy":"2022-05-21T15:44:57.765358Z","iopub.execute_input":"2022-05-21T15:44:57.765796Z","iopub.status.idle":"2022-05-21T15:44:57.772120Z","shell.execute_reply.started":"2022-05-21T15:44:57.765761Z","shell.execute_reply":"2022-05-21T15:44:57.771399Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Combining Title and Text","metadata":{}},{"cell_type":"code","source":"\nreal[\"text\"] = real[\"title\"] + \" \" + real[\"text\"]\nfake[\"text\"] = fake[\"title\"] + \" \" + fake[\"text\"]","metadata":{"id":"SYj4Dnm7dDLh","execution":{"iopub.status.busy":"2022-05-21T15:44:57.773444Z","iopub.execute_input":"2022-05-21T15:44:57.774004Z","iopub.status.idle":"2022-05-21T15:44:58.009839Z","shell.execute_reply.started":"2022-05-21T15:44:57.773962Z","shell.execute_reply":"2022-05-21T15:44:58.009114Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Subject is Diffrent for real and fake => dropping ","metadata":{}},{"cell_type":"code","source":"real = real.drop([\"subject\", \"date\",\"title\",  \"publisher\"], axis=1)\nfake = fake.drop([\"subject\", \"date\", \"title\"], axis=1)","metadata":{"id":"jiBm_dDWdDLw","execution":{"iopub.status.busy":"2022-05-21T15:44:58.011448Z","iopub.execute_input":"2022-05-21T15:44:58.011974Z","iopub.status.idle":"2022-05-21T15:44:58.022818Z","shell.execute_reply.started":"2022-05-21T15:44:58.011938Z","shell.execute_reply":"2022-05-21T15:44:58.021902Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Combining both into new dataframe","metadata":{}},{"cell_type":"code","source":"data = real.append(fake, ignore_index=True)\ndel real, fake","metadata":{"id":"5_L4CePKdDME","execution":{"iopub.status.busy":"2022-05-21T15:44:58.024427Z","iopub.execute_input":"2022-05-21T15:44:58.024813Z","iopub.status.idle":"2022-05-21T15:44:58.030870Z","shell.execute_reply.started":"2022-05-21T15:44:58.024780Z","shell.execute_reply":"2022-05-21T15:44:58.030112Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Removing StopWords, Punctuations and single-character words","metadata":{}},{"cell_type":"markdown","source":"# Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\n","metadata":{}},{"cell_type":"code","source":"y = data[\"class\"].values\nX = []\nstop_words = set(nltk.corpus.stopwords.words(\"english\"))\ntokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\nfor par in data[\"text\"].values:\n    tmp = []\n    sentences = nltk.sent_tokenize(par)\n    for sent in sentences:\n        sent = sent.lower()\n        tokens = tokenizer.tokenize(sent)\n        filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n        tmp.extend(filtered_words)\n    X.append(tmp)\n\ndel data","metadata":{"id":"H07kA_z6dDMX","execution":{"iopub.status.busy":"2022-05-21T15:44:58.040661Z","iopub.execute_input":"2022-05-21T15:44:58.041087Z","iopub.status.idle":"2022-05-21T15:45:57.915000Z","shell.execute_reply.started":"2022-05-21T15:44:58.041048Z","shell.execute_reply":"2022-05-21T15:45:57.914303Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Vectorization -- Word2Vec\n\nWord2Vec is one of the most popular technique to learn word embeddings using shallow neural network. It was developed by Tomas Mikolov in 2013 at Google.\n\nWord embedding is the most popular representation of document vocabulary. It is capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words, etc.\n\n\n\n","metadata":{"id":"ZFLUPXGodDMv"}},{"cell_type":"markdown","source":"#### Let's create and check our own Word2Vec model with **gensim**","metadata":{"id":"JHKIgurRdDM2"}},{"cell_type":"code","source":"import gensim","metadata":{"id":"GoQRvjexdDM5","execution":{"iopub.status.busy":"2022-05-21T15:45:57.916129Z","iopub.execute_input":"2022-05-21T15:45:57.916392Z","iopub.status.idle":"2022-05-21T15:46:04.357123Z","shell.execute_reply.started":"2022-05-21T15:45:57.916361Z","shell.execute_reply":"2022-05-21T15:46:04.356407Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Dimension of vectors we are generating","metadata":{}},{"cell_type":"code","source":"EMBEDDING_DIM = 100\n\n#Creating Word Vectors by Word2Vec Method\nw2v_model = gensim.models.Word2Vec(sentences=X, size=EMBEDDING_DIM, window=5, min_count=1)","metadata":{"id":"8JpCLfaldDNW","execution":{"iopub.status.busy":"2022-05-21T15:46:04.358381Z","iopub.execute_input":"2022-05-21T15:46:04.358668Z","iopub.status.idle":"2022-05-21T15:48:18.954964Z","shell.execute_reply.started":"2022-05-21T15:46:04.358634Z","shell.execute_reply":"2022-05-21T15:48:18.954146Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Vocab Size","metadata":{}},{"cell_type":"code","source":"len(w2v_model.wv.vocab)\n\n# Represented each of 122248 words by a 100dim vector.","metadata":{"id":"DP1nyaGqdDNr","outputId":"f45e5906-dc2b-448b-fc38-f3fca9901e1f","execution":{"iopub.status.busy":"2022-05-21T15:48:18.956282Z","iopub.execute_input":"2022-05-21T15:48:18.956569Z","iopub.status.idle":"2022-05-21T15:48:18.963413Z","shell.execute_reply.started":"2022-05-21T15:48:18.956535Z","shell.execute_reply":"2022-05-21T15:48:18.962512Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Exploring Vectors\n","metadata":{"id":"iloSEX4NdDN_"}},{"cell_type":"markdown","source":"# See a sample vector for random word, say Corona ","metadata":{}},{"cell_type":"code","source":"w2v_model[\"corona\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:48:18.965189Z","iopub.execute_input":"2022-05-21T15:48:18.965785Z","iopub.status.idle":"2022-05-21T15:48:18.979715Z","shell.execute_reply.started":"2022-05-21T15:48:18.965750Z","shell.execute_reply":"2022-05-21T15:48:18.978611Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.most_similar(\"iran\")","metadata":{"id":"s3eymov_dDOC","outputId":"781b409b-421f-4284-bc0c-c8952db524fd","execution":{"iopub.status.busy":"2022-05-21T15:48:18.980934Z","iopub.execute_input":"2022-05-21T15:48:18.981391Z","iopub.status.idle":"2022-05-21T15:48:19.055531Z","shell.execute_reply.started":"2022-05-21T15:48:18.981357Z","shell.execute_reply":"2022-05-21T15:48:19.054738Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.most_similar(\"fbi\")","metadata":{"id":"iLwtmvpydDOP","outputId":"ba2f4e47-1f96-4fd4-fe7d-a1740f684b88","execution":{"iopub.status.busy":"2022-05-21T15:48:19.063250Z","iopub.execute_input":"2022-05-21T15:48:19.063704Z","iopub.status.idle":"2022-05-21T15:48:19.077828Z","shell.execute_reply.started":"2022-05-21T15:48:19.063668Z","shell.execute_reply":"2022-05-21T15:48:19.076995Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.most_similar(\"facebook\")","metadata":{"id":"UCYch1mUt1Cn","outputId":"06447659-bcdf-4ee4-8d08-4888a3cb43d5","execution":{"iopub.status.busy":"2022-05-21T15:48:19.079174Z","iopub.execute_input":"2022-05-21T15:48:19.079583Z","iopub.status.idle":"2022-05-21T15:48:19.095271Z","shell.execute_reply.started":"2022-05-21T15:48:19.079549Z","shell.execute_reply":"2022-05-21T15:48:19.094535Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.most_similar(\"computer\")","metadata":{"id":"ErNpsa8Lt8Vi","outputId":"d887ca8d-70e5-4f2b-9578-f8cdfe94f769","execution":{"iopub.status.busy":"2022-05-21T15:48:19.096421Z","iopub.execute_input":"2022-05-21T15:48:19.096848Z","iopub.status.idle":"2022-05-21T15:48:19.112741Z","shell.execute_reply.started":"2022-05-21T15:48:19.096813Z","shell.execute_reply":"2022-05-21T15:48:19.111887Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Feeding US Presidents","metadata":{}},{"cell_type":"code","source":"w2v_model.wv.most_similar(positive=[\"trump\",\"obama\", \"clinton\"])\n#First was Bush","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:48:19.113933Z","iopub.execute_input":"2022-05-21T15:48:19.114322Z","iopub.status.idle":"2022-05-21T15:48:19.129177Z","shell.execute_reply.started":"2022-05-21T15:48:19.114288Z","shell.execute_reply":"2022-05-21T15:48:19.128430Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**Looking at the similar words, vectors are well formed for these words :)**\n\n\nThese Vectors will be passed to LSTM/GRU instead of words. 1D-CNN can further be used to extract features from the vectors. \n\n\nKeras has implementation called \"**Embedding Layer**\" which would create word embeddings(vectors). Since we did that with gensim's word2vec, we will load these vectors into embedding layer and make the layer non-trainable.\n\n\n","metadata":{"id":"1jDnzu5Htzsp"}},{"cell_type":"markdown","source":"Tokenizer can represent each word by number. Since we cannot pass string words to embedding layer, thus need some way to represent each words by numbers.","metadata":{}},{"cell_type":"markdown","source":"# Tokenizing Text -> Repsesenting each word by a number\n# Mapping of orginal word to number is preserved in word_index property of tokenizer\n\n# Tokenized applies basic processing like changing it yo lower case, explicitely setting that as False","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\n\nX = tokenizer.texts_to_sequences(X)","metadata":{"id":"8nQ8aN_brt-m","execution":{"iopub.status.busy":"2022-05-21T15:48:19.130310Z","iopub.execute_input":"2022-05-21T15:48:19.130716Z","iopub.status.idle":"2022-05-21T15:48:34.133919Z","shell.execute_reply.started":"2022-05-21T15:48:19.130681Z","shell.execute_reply":"2022-05-21T15:48:34.133207Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Checking the first 10 words of first news # every word has been represented with a number","metadata":{}},{"cell_type":"code","source":"X[0][:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:48:34.135610Z","iopub.execute_input":"2022-05-21T15:48:34.135867Z","iopub.status.idle":"2022-05-21T15:48:34.141593Z","shell.execute_reply.started":"2022-05-21T15:48:34.135834Z","shell.execute_reply":"2022-05-21T15:48:34.140887Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Mapping is preserved in dictionary -> word_index property of instance","metadata":{}},{"cell_type":"code","source":"word_index = tokenizer.word_index\nfor word, num in word_index.items():\n    print(f\"{word} -> {num}\")\n    if num == 10:\n        break        ","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:48:34.142938Z","iopub.execute_input":"2022-05-21T15:48:34.143447Z","iopub.status.idle":"2022-05-21T15:48:34.153617Z","shell.execute_reply.started":"2022-05-21T15:48:34.143413Z","shell.execute_reply":"2022-05-21T15:48:34.152674Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"**Notice it starts with 1**\n","metadata":{}},{"cell_type":"markdown","source":"We can pass numerical representation of words into neural network.\n\nWe can use Many-To-One (Sequence-To-Word) Model of RNN, as we have many words in news as input and one output ie Probability of being Real.\n\nFor Many-To-One model, lets use a fixed size input. \n","metadata":{}},{"cell_type":"markdown","source":"# Histogram for no of words in news shows that most news article are under 700 words.\n# Keeping each news small and truncate all news to 700 while tokenizing","metadata":{}},{"cell_type":"code","source":"plt.hist([len(x) for x in X], bins=500)\nplt.show()\n\n# Its heavily skewed.\n# Truncate these outliers","metadata":{"id":"xQYGbmRZrtrO","outputId":"65ebe7a7-944b-4331-d300-41b86922377b","execution":{"iopub.status.busy":"2022-05-21T15:48:34.155037Z","iopub.execute_input":"2022-05-21T15:48:34.155442Z","iopub.status.idle":"2022-05-21T15:48:35.048262Z","shell.execute_reply.started":"2022-05-21T15:48:34.155407Z","shell.execute_reply":"2022-05-21T15:48:35.047599Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"nos = np.array([len(x) for x in X])\nlen(nos[nos  < 700])\n# Out of 48k news, 44k have less than 700 words","metadata":{"id":"ObfiqLhyrtxY","outputId":"544f333e-5642-426c-d460-ce0326789d5f","execution":{"iopub.status.busy":"2022-05-21T15:48:35.049437Z","iopub.execute_input":"2022-05-21T15:48:35.049715Z","iopub.status.idle":"2022-05-21T15:48:35.073105Z","shell.execute_reply.started":"2022-05-21T15:48:35.049678Z","shell.execute_reply":"2022-05-21T15:48:35.072550Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Keep all news to 700, add padding to news with less than 700 words and truncating long ones","metadata":{}},{"cell_type":"code","source":"maxlen = 700 \n\n#Making all news of size maxlen defined above\nX = pad_sequences(X, maxlen=maxlen)","metadata":{"id":"qf-4aQnqrt6M","execution":{"iopub.status.busy":"2022-05-21T15:48:35.075295Z","iopub.execute_input":"2022-05-21T15:48:35.075829Z","iopub.status.idle":"2022-05-21T15:48:37.348374Z","shell.execute_reply.started":"2022-05-21T15:48:35.075794Z","shell.execute_reply":"2022-05-21T15:48:37.347589Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#all news has 700 words (in numerical form now). If they had less words, they have been padded with 0","metadata":{}},{"cell_type":"code","source":"# 0 is not associated to any word, as mapping of words started from 1\n# 0 will also be used later, if unknows word is encountered in test set\nlen(X[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:48:37.353258Z","iopub.execute_input":"2022-05-21T15:48:37.353517Z","iopub.status.idle":"2022-05-21T15:48:37.360089Z","shell.execute_reply.started":"2022-05-21T15:48:37.353483Z","shell.execute_reply":"2022-05-21T15:48:37.359115Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Adding 1 because of reserved 0 index\n# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n# Thus our vocab size inceeases by 1\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"id":"0q3cFF-N2Mix","execution":{"iopub.status.busy":"2022-05-21T15:48:37.361787Z","iopub.execute_input":"2022-05-21T15:48:37.362450Z","iopub.status.idle":"2022-05-21T15:48:37.367810Z","shell.execute_reply.started":"2022-05-21T15:48:37.362409Z","shell.execute_reply":"2022-05-21T15:48:37.366844Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Function to create weight matrix from word2vec gensim model","metadata":{}},{"cell_type":"code","source":"def get_weight_matrix(model, vocab):\n    # total vocabulary size plus 0 for unknown words\n    vocab_size = len(vocab) + 1\n    # define weight matrix dimensions with all 0\n    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n    # step vocab, store vectors using the Tokenizer's integer mapping\n    for word, i in vocab.items():\n        weight_matrix[i] = model[word]\n    return weight_matrix","metadata":{"id":"wFjoigbq43SM","execution":{"iopub.status.busy":"2022-05-21T15:48:37.369396Z","iopub.execute_input":"2022-05-21T15:48:37.370132Z","iopub.status.idle":"2022-05-21T15:48:37.377657Z","shell.execute_reply.started":"2022-05-21T15:48:37.370021Z","shell.execute_reply":"2022-05-21T15:48:37.376965Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"We Create a matrix of mapping between word-index and vectors. We use this as weights in embedding layer\n\nEmbedding layer accepts numecical-token of word and outputs corresponding vercor to inner layer.\n\nIt sends vector of zeros to next layer for unknown words which would be tokenized to 0.\n\n\nInput length of Embedding Layer is the length of each news (700 now due to padding and truncating)","metadata":{}},{"cell_type":"markdown","source":"# Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer","metadata":{}},{"cell_type":"code","source":"embedding_vectors = get_weight_matrix(w2v_model, word_index)","metadata":{"id":"o2etO3jIrtvM","execution":{"iopub.status.busy":"2022-05-21T15:48:37.379430Z","iopub.execute_input":"2022-05-21T15:48:37.379950Z","iopub.status.idle":"2022-05-21T15:48:38.335456Z","shell.execute_reply.started":"2022-05-21T15:48:37.379910Z","shell.execute_reply":"2022-05-21T15:48:38.334755Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Defining Neural Network","metadata":{}},{"cell_type":"code","source":"\nmodel = Sequential()\n#Non-trainable embeddidng layer\nmodel.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=False))\n#LSTM \nmodel.add(LSTM(units=128))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n\ndel embedding_vectors","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:48:38.336888Z","iopub.execute_input":"2022-05-21T15:48:38.337302Z","iopub.status.idle":"2022-05-21T15:48:40.954444Z","shell.execute_reply.started":"2022-05-21T15:48:38.337265Z","shell.execute_reply":"2022-05-21T15:48:40.953687Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"B9QlV7NrID0_","outputId":"7388db21-77ab-4b6f-ac1d-ac3e30ec533c","execution":{"iopub.status.busy":"2022-05-21T15:48:40.957153Z","iopub.execute_input":"2022-05-21T15:48:40.957466Z","iopub.status.idle":"2022-05-21T15:48:40.965668Z","shell.execute_reply.started":"2022-05-21T15:48:40.957429Z","shell.execute_reply":"2022-05-21T15:48:40.964742Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"#Train test split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y) ","metadata":{"id":"II-pr_sgHpcX","execution":{"iopub.status.busy":"2022-05-21T15:48:40.967129Z","iopub.execute_input":"2022-05-21T15:48:40.967745Z","iopub.status.idle":"2022-05-21T15:48:41.021201Z","shell.execute_reply.started":"2022-05-21T15:48:40.967707Z","shell.execute_reply":"2022-05-21T15:48:41.020420Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, validation_split=0.3, epochs=6)","metadata":{"id":"GkCiftes3JD6","outputId":"3741f776-453b-418f-9d91-d572f96cb720","execution":{"iopub.status.busy":"2022-05-21T15:48:41.022403Z","iopub.execute_input":"2022-05-21T15:48:41.022933Z","iopub.status.idle":"2022-05-21T15:51:56.660230Z","shell.execute_reply.started":"2022-05-21T15:48:41.022893Z","shell.execute_reply":"2022-05-21T15:51:56.659586Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"# Prediction is in probability of news being real, so converting into classes","metadata":{}},{"cell_type":"code","source":"# Class 0 (Fake) if predicted prob < 0.5, else class 1 (Real)\ny_pred = (model.predict(X_test) >= 0.5).astype(\"int\")","metadata":{"id":"swVt7TjQzNCM","execution":{"iopub.status.busy":"2022-05-21T15:51:56.661580Z","iopub.execute_input":"2022-05-21T15:51:56.661863Z","iopub.status.idle":"2022-05-21T15:52:02.065610Z","shell.execute_reply.started":"2022-05-21T15:51:56.661829Z","shell.execute_reply":"2022-05-21T15:52:02.064869Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"id":"5l6MGjUTJntM","outputId":"60e58b71-85e3-4a57-8663-aacde39d6dee","execution":{"iopub.status.busy":"2022-05-21T15:52:02.066932Z","iopub.execute_input":"2022-05-21T15:52:02.067194Z","iopub.status.idle":"2022-05-21T15:52:02.074924Z","shell.execute_reply.started":"2022-05-21T15:52:02.067162Z","shell.execute_reply":"2022-05-21T15:52:02.074218Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"id":"lAx6hEfbJqvm","outputId":"5c5b56cc-acd8-41b2-e9d8-4e5114fa7ba5","execution":{"iopub.status.busy":"2022-05-21T15:52:02.076200Z","iopub.execute_input":"2022-05-21T15:52:02.076708Z","iopub.status.idle":"2022-05-21T15:52:02.103764Z","shell.execute_reply.started":"2022-05-21T15:52:02.076670Z","shell.execute_reply":"2022-05-21T15:52:02.103008Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"del model","metadata":{"id":"8ncDQMKRyE55","execution":{"iopub.status.busy":"2022-05-21T15:52:02.104986Z","iopub.execute_input":"2022-05-21T15:52:02.105300Z","iopub.status.idle":"2022-05-21T15:52:02.108778Z","shell.execute_reply.started":"2022-05-21T15:52:02.105264Z","shell.execute_reply":"2022-05-21T15:52:02.108045Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"### Using Pre-Trained Word2Vec Vectors\n\n**Requirements\nRAM: 12GB  and HardDisk Space: 4GB**","metadata":{"id":"cC8v4HlZdLcu"}},{"cell_type":"markdown","source":"# Invoke garbage collector to free ram","metadata":{}},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:52:02.110044Z","iopub.execute_input":"2022-05-21T15:52:02.110601Z","iopub.status.idle":"2022-05-21T15:52:02.280584Z","shell.execute_reply.started":"2022-05-21T15:52:02.110565Z","shell.execute_reply":"2022-05-21T15:52:02.278842Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from gensim.models.keyedvectors import KeyedVectors","metadata":{"id":"qk_AEI94LmHI","execution":{"iopub.status.busy":"2022-05-21T15:52:02.281929Z","iopub.execute_input":"2022-05-21T15:52:02.282177Z","iopub.status.idle":"2022-05-21T15:52:02.286272Z","shell.execute_reply.started":"2022-05-21T15:52:02.282144Z","shell.execute_reply":"2022-05-21T15:52:02.285513Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Requires RAM \nword_vectors = KeyedVectors.load_word2vec_format('../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin', binary=True)\nEMBEDDING_DIM=300","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:52:02.287983Z","iopub.execute_input":"2022-05-21T15:52:02.288308Z","iopub.status.idle":"2022-05-21T15:54:04.910170Z","shell.execute_reply.started":"2022-05-21T15:52:02.288273Z","shell.execute_reply":"2022-05-21T15:54:04.909451Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### Exploring these trained Vectors","metadata":{"id":"iLcTApQpgXpe"}},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    try:\n#         embedding_vector = word_vectors[word]\n        embedding_matrix[i] = embedding_vector\n    except KeyError:\n        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n\n# del word_vectors ","metadata":{"id":"sdkVbKXqfJGh","execution":{"iopub.status.busy":"2022-05-21T16:00:08.416925Z","iopub.execute_input":"2022-05-21T16:00:08.417198Z","iopub.status.idle":"2022-05-21T16:00:08.700725Z","shell.execute_reply.started":"2022-05-21T16:00:08.417169Z","shell.execute_reply":"2022-05-21T16:00:08.699958Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=maxlen, trainable=False))\nmodel.add(Conv1D(activation='relu', filters=4, kernel_size=4))\nmodel.add(MaxPool1D())\nmodel.add(LSTM(units=128))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n\ndel embedding_matrix","metadata":{"id":"UoSJl84gLZi8","execution":{"iopub.status.busy":"2022-05-21T15:59:31.568892Z","iopub.execute_input":"2022-05-21T15:59:31.569155Z","iopub.status.idle":"2022-05-21T15:59:32.448665Z","shell.execute_reply.started":"2022-05-21T15:59:31.569127Z","shell.execute_reply":"2022-05-21T15:59:32.447973Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"fzvS8m5LLZtu","outputId":"118799c3-468b-4547-cdec-dbd1a196e518","execution":{"iopub.status.busy":"2022-05-21T15:54:08.234393Z","iopub.execute_input":"2022-05-21T15:54:08.234614Z","iopub.status.idle":"2022-05-21T15:54:08.243737Z","shell.execute_reply.started":"2022-05-21T15:54:08.234590Z","shell.execute_reply":"2022-05-21T15:54:08.242831Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, validation_split=0.3, epochs=12)","metadata":{"id":"OMJklhVAjNGZ","outputId":"1cb4a101-3a36-4563-a40a-9ccfaf12c945","execution":{"iopub.status.busy":"2022-05-21T15:54:08.244964Z","iopub.execute_input":"2022-05-21T15:54:08.245287Z","iopub.status.idle":"2022-05-21T15:58:50.116558Z","shell.execute_reply.started":"2022-05-21T15:54:08.245249Z","shell.execute_reply":"2022-05-21T15:58:50.115626Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"y_pred = (model.predict(X_test) > 0.5).astype(\"int\")","metadata":{"id":"ZaUCmKYojQJS","execution":{"iopub.status.busy":"2022-05-21T15:58:50.118293Z","iopub.execute_input":"2022-05-21T15:58:50.118601Z","iopub.status.idle":"2022-05-21T15:58:54.767708Z","shell.execute_reply.started":"2022-05-21T15:58:50.118562Z","shell.execute_reply":"2022-05-21T15:58:54.766292Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"id":"CkZtLGNYjXnu","outputId":"5562a291-d9f5-4e7d-9ea1-bd76cabba413","execution":{"iopub.status.busy":"2022-05-21T15:58:54.770101Z","iopub.execute_input":"2022-05-21T15:58:54.770790Z","iopub.status.idle":"2022-05-21T15:58:54.790054Z","shell.execute_reply.started":"2022-05-21T15:58:54.770706Z","shell.execute_reply":"2022-05-21T15:58:54.789292Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"id":"FTqJSkXSjXrf","outputId":"5809f01a-3a4d-4c3e-8f29-534206ce23dc","execution":{"iopub.status.busy":"2022-05-21T15:58:54.791450Z","iopub.execute_input":"2022-05-21T15:58:54.792171Z","iopub.status.idle":"2022-05-21T15:58:54.830878Z","shell.execute_reply.started":"2022-05-21T15:58:54.792130Z","shell.execute_reply":"2022-05-21T15:58:54.830174Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"**Final Results:**\nAlong with comparison from other top models \nBased on the chosen model's accuracy.\n1. By selecting lbfgs as the solver and increasing the maximum number of iterations to 200, we can get an accuracy of 90.77 percent on the testing data for Logistic Regression with spaCy vectors as input features.\n2. With spaCy vectors as input features, the decision tree classifier achieves an accuracy of 85.51 percent.\n3. Logistic Regression with textual data as an input feature and Count Vectorizer and TFIDF Transformer in pipeline achieves 98.93% accuracy.\n4. A Decision Tree Classifier using textual data as an input feature and Count Vectorizer and TFIDF Transformer in the pipeline achieves 99.63 percent accuracy.\n5. Using 1000 input features, an artificial neural network constructed with keras and tensorflow backend with the Sequential Model and dense layers achieves an accuracy of 99.28 percent.\n6. An Artificial Neural Network built using Keras and Tensorflow backends with the Sequential Model and dense layers achieves an accuracy of 99.21 percent on testing data with 10000 input features.\nBased on the F1-scores of the selected model, we can calculate the number of false positives and false negatives. Overall, we get an accuracy of 98.93%.\n1. By selecting lbfgs as the solver and increasing the maximum number of iterations to 200, we can obtain a f1-score of 90.42 percent on the testing data for Logistic Regression with spaCy vectors as input features.\n2. A decision tree classifier with spaCy vectors as input features achieves a f1-score of 84.49 percent.\n3. Logistic Regression with textual data as an input feature and Count Vectorizer and TFIDF Transformer in the pipeline yields a f1 of 98.81%.\n4. A Decision Tree Classifier using textual data as an input feature and Count Vectorizer and TFIDF Transformer in the pipeline produces a f1-score of 99.61 percent.\n5. Keras with Tensorflow backend Artificial Neural Network with Sequential Model and Dense Layers supply us with a f1-score of 99.25 percent on the testing data with 1000 input features.\n6. An artificial neural network built using Keras and Tensorflow backends with the Sequential Model and dense layers achieves a f1-score of 99.17 percent on testing data with 10000 input features.\nAlso, an F1 score comparable to that of accuracy demonstrates how accurate our model is in forecasting.\n\nvalues by learning whether it is real or false news via model training","metadata":{}},{"cell_type":"markdown","source":"**Future Work:**\n1. Gathering specific news-related tweets.\n2. Using the same Decision Tree Classifier and pipeline, we will forecast whether or not this is false news.\n\n3. Another suggestion is to utilise the same for the credibility score assignment of a certain tweet, which is slightly different from this.","metadata":{}},{"cell_type":"markdown","source":"**Conclusions:**\nUsing Pre-Trained Word2Vec Vectors in a pipeline with we've achieved maximum accuracy, recall and F1 score of about 99%, but there is always room for improvement. Various things, such as tweaking the hyperparameters, can be done in the future to improve the accuracy and f1 score based on another dataset. Use of tensors may enhance the overall results.","metadata":{}}]}